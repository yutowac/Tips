{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3136,"databundleVersionId":26502,"sourceType":"competition"}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/yutodennou/tips-auto-model-generate-by-open-interpreter?scriptVersionId=169535851\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"<a id=\"1\"></a>\n# <div style=\"box-shadow: rgba(0, 0, 0, 0.16) 0px 1px 4px inset, rgb(51, 51, 51) 0px 0px 0px 3px inset; padding:20px; font-size:32px; font-family: consolas; text-align:center; display:fill; border-radius:15px;  color:rgb(34, 34, 34);\"> <b> 1. Purposeüéâ </b></div>","metadata":{}},{"cell_type":"markdown","source":"**Open Interpreter makes below codes automatically by simple prompt.  \nHere is an easy way to analyze using Open Interpreter, even if someone is not familiar with preprocessing or models.** ","metadata":{}},{"cell_type":"markdown","source":"```python\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import train_test_split\n\n# Encode categorical variables\nlabel_encoder = LabelEncoder()\ntrain_data['Sex'] = label_encoder.fit_transform(train_data['Sex'])\ntest_data['Sex'] = label_encoder.transform(test_data['Sex']) \n\n# Fill missing values\nimputer = SimpleImputer(strategy='mean')\ntrain_data['Age'] = imputer.fit_transform(train_data[['Age']])\ntest_data['Age'] = imputer.transform(test_data[['Age']])\ntrain_data['Fare'] = imputer.fit_transform(train_data[['Fare']])\ntest_data['Fare'] = imputer.transform(test_data[['Fare']])\n\n# Split data into features and target\nX_train = train_data.drop(['Survived'], axis=1)\ny_train = train_data['Survived']\nX_test = test_data \n\n\n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nimport xgboost as xgb\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import VotingClassifier\nimport pickle\n\n# Define the models\ndecision_tree = DecisionTreeClassifier()\nrandom_forest = RandomForestClassifier()\nxgboost = xgb.XGBClassifier()\n\n# Create the ensemble model\nensemble_model = VotingClassifier(estimators=[('dt', decision_tree), ('rf', random_forest), ('xgb', xgboost)], voting='hard')\n\n# Perform cross-validation\ndecision_tree_scores = cross_val_score(decision_tree, X_train, y_train, cv=4)\nrandom_forest_scores = cross_val_score(random_forest, X_train, y_train, cv=4)\nxgboost_scores = cross_val_score(xgboost, X_train, y_train, cv=4)\nensemble_scores = cross_val_score(ensemble_model, X_train, y_train, cv=4)\n\n# Calculate average accuracy\ndecision_tree_avg_accuracy = decision_tree_scores.mean()\nrandom_forest_avg_accuracy = random_forest_scores.mean()\nxgboost_avg_accuracy = xgboost_scores.mean()\nensemble_avg_accuracy = ensemble_scores.mean()\n\n# Save the best model as a pickle file\nbest_model = max(decision_tree_avg_accuracy, random_forest_avg_accuracy, xgboost_avg_accuracy, ensemble_avg_accuracy)\nif best_model == decision_tree_avg_accuracy:\n    pickle.dump(decision_tree, open('decision_tree_model.pkl', 'wb'))\nelif best_model == random_forest_avg_accuracy:\n    pickle.dump(random_forest, open('random_forest_model.pkl', 'wb'))\nelif best_model == xgboost_avg_accuracy:\n    pickle.dump(xgboost, open('xgboost_model.pkl', 'wb'))\nelse:\n    pickle.dump(ensemble_model, open('ensemble_model.pkl', 'wb'))\n\n\n```","metadata":{}},{"cell_type":"markdown","source":"<a id=\"2\"></a>\n# <div style=\"box-shadow: rgba(0, 0, 0, 0.16) 0px 1px 4px inset, rgb(51, 51, 51) 0px 0px 0px 3px inset; padding:20px; font-size:32px; font-family: consolas; text-align:center; display:fill; border-radius:15px;  color:rgb(34, 34, 34);\"> <b> 2. Import LibraryüóÇÔ∏è </b></div>","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-17T10:06:53.795443Z","iopub.execute_input":"2023-12-17T10:06:53.796176Z","iopub.status.idle":"2023-12-17T10:06:54.104887Z","shell.execute_reply.started":"2023-12-17T10:06:53.796141Z","shell.execute_reply":"2023-12-17T10:06:54.104069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install open-interpreter","metadata":{"execution":{"iopub.status.busy":"2023-12-17T10:06:54.106614Z","iopub.execute_input":"2023-12-17T10:06:54.106994Z","iopub.status.idle":"2023-12-17T10:07:19.591028Z","shell.execute_reply.started":"2023-12-17T10:06:54.10697Z","shell.execute_reply":"2023-12-17T10:07:19.590411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"3\"></a>\n# <div style=\"box-shadow: rgba(0, 0, 0, 0.16) 0px 1px 4px inset, rgb(51, 51, 51) 0px 0px 0px 3px inset; padding:20px; font-size:32px; font-family: consolas; text-align:center; display:fill; border-radius:15px;  color:rgb(34, 34, 34);\"> <b> 3. Set Up‚öôÔ∏è</b></div>\n","metadata":{"execution":{"iopub.status.busy":"2023-12-12T06:50:57.541341Z","iopub.execute_input":"2023-12-12T06:50:57.541864Z","iopub.status.idle":"2023-12-12T06:50:57.580779Z","shell.execute_reply.started":"2023-12-12T06:50:57.541812Z","shell.execute_reply":"2023-12-12T06:50:57.579083Z"}}},{"cell_type":"markdown","source":"**If you run the following code and it does not work, please stop the kernel(\"Restart & clear cell output\") and run again from here**","metadata":{}},{"cell_type":"code","source":"import interpreter\ninterpreter.auto_run = True\n\n# Use GPT-3.5-turboÔºé\ninterpreter.model = \"gpt-3.5-turbo\"","metadata":{"execution":{"iopub.status.busy":"2023-12-17T10:07:19.591879Z","iopub.execute_input":"2023-12-17T10:07:19.592125Z","iopub.status.idle":"2023-12-17T10:07:21.811802Z","shell.execute_reply.started":"2023-12-17T10:07:19.592101Z","shell.execute_reply":"2023-12-17T10:07:21.81095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Your API key from here -> https://platform.openai.com/api-keys\ninterpreter.api_key = \"YOUR API KEY\"","metadata":{"execution":{"iopub.status.busy":"2023-12-17T10:07:21.813768Z","iopub.execute_input":"2023-12-17T10:07:21.814208Z","iopub.status.idle":"2023-12-17T10:07:21.818474Z","shell.execute_reply.started":"2023-12-17T10:07:21.814184Z","shell.execute_reply":"2023-12-17T10:07:21.817502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"4\"></a>\n# <div style=\"box-shadow: rgba(0, 0, 0, 0.16) 0px 1px 4px inset, rgb(51, 51, 51) 0px 0px 0px 3px inset; padding:20px; font-size:32px; font-family: consolas; text-align:center; display:fill; border-radius:15px;  color:rgb(34, 34, 34);\"> <b> 4. Generate Codes üëâ</b></div>\n","metadata":{}},{"cell_type":"code","source":"text = \"\"\"\n# Read csv data as dataset from '/kaggle/input/titanic/train.csv' as train data and '/kaggle/input/titanic/test.csv' as test data.\n# Using the dataset, test the Decision Tree, Random Forest, XGBoost and an ensemble of the three models to see which is the most accurate. \n# Before testing, use onehot encoding to categorical data columns.\n# Before testing, drop object data columns like 'Name','Ticket' and 'Cabin' columns.\n# Before testing, fill in any missing values with representative values\n# The validation should be based on the average of the 4-fold cross-validation results.\n# Run the generated code, and if an error occurs, repeat the modification until the error disappears\n# Save model as pickle file\n# Save codes as notebook file\n\"\"\"\n\nResults = interpreter.chat(text)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T10:13:13.096277Z","iopub.execute_input":"2023-12-17T10:13:13.096608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Generated example","metadata":{}},{"cell_type":"markdown","source":"  It seems that there is an error in the code. The error message suggests that there is an issue with converting   \n  a string to a float. This could be due to missing or incorrect data in the dataset.                              \n\n  To fix this issue, we can modify the code to handle missing values and convert categorical variables to          \n  numerical values. We can use the OneHotEncoder to encode categorical variables and the SimpleImputer to fill     \n  missing values.                                                                                                  \n\n  Here is the updated code:","metadata":{}},{"cell_type":"code","source":"\nimport pandas as pd                                                                                             \nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder                                                   \nfrom sklearn.impute import SimpleImputer                                                                        \nfrom sklearn.ensemble import RandomForestClassifier                                                             \nfrom sklearn.model_selection import cross_val_score                                                             \nimport pickle                                                                                                   \n\n# Read the train dataset from CSV                                                                               \ndata_train = pd.read_csv('/kaggle/input/titanic/train.csv')                                                     \n\n# Read the test dataset from CSV                                                                                \ndata_test = pd.read_csv('/kaggle/input/titanic/test.csv')                                                       \n\n# Combine train and test data                                                                                   \ndata = pd.concat([data_train, data_test], axis=0)                                                               \n\n# Encode categorical variables                                                                                  \nlabel_encoder = LabelEncoder()                                                                                  \ndata['Sex'] = label_encoder.fit_transform(data['Sex'])                                                          \n\n# Fill missing values                                                                                           \nimputer = SimpleImputer(strategy='mean')                                                                        \ndata['Age'] = imputer.fit_transform(data[['Age']])                                                              \ndata['Fare'] = imputer.fit_transform(data[['Fare']]])                                                           \n\n# Split data into train and test                                                                                \nX_train = data_train.drop(['Survived'], axis=1)                                                                 \ny_train = data_train['Survived']                                                                                \nX_test = data_test                                                                                              \n\n# Create the model                                                                                              \nmodel = RandomForestClassifier()                                                                                \n\n# Perform k-fold cross-validation                                                                               \nscores = cross_val_score(model, X_train, y_train, cv=5)                                                         \n\n# Print the scores                                                                                              \nfor fold, score in enumerate(scores, start=1):                                                                  \n    print(f\"Fold {fold}: {score}\")                                                                              \n\n# Save the model as a pickle file                                                                               \npickle.dump(model, open('titanic_model.pkl', 'wb'))                                                                                                                                                                        \n\nwith open('titanic_processing_code.py', 'w') as f:                                                              \n    f.write(code)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"  Please try running this updated code and let me know if you encounter any further issues.  ","metadata":{}},{"cell_type":"markdown","source":"**By above simple code lines, what I put in \"1.Purpose\" generats as one result.\nThis is really easy way to get fundamental models!!**","metadata":{}},{"cell_type":"markdown","source":"<a id=\"5\"></a>\n# <div style=\"box-shadow: rgba(0, 0, 0, 0.16) 0px 1px 4px inset, rgb(51, 51, 51) 0px 0px 0px 3px inset; padding:20px; font-size:32px; font-family: consolas; text-align:center; display:fill; border-radius:15px;  color:rgb(34, 34, 34);\"> <b> Bonus: Bad ExampleüôÖ </b></div>","metadata":{}},{"cell_type":"code","source":"text = \"\"\"\n# Read csv data as dataset from '/kaggle/input/titanic/train.csv' as train data and '/kaggle/input/titanic/test.csv' as test data.\n# Using the dataset, make one accuraet model. \n# The validation method is k-fold cross-validation.\n# show the scores by print()\n# Save model and processing code\n\"\"\"\n\nresults = interpreter.chat(text)","metadata":{"execution":{"iopub.status.busy":"2023-12-11T08:16:57.558497Z","iopub.execute_input":"2023-12-11T08:16:57.559111Z","iopub.status.idle":"2023-12-11T08:20:14.339506Z","shell.execute_reply.started":"2023-12-11T08:16:57.559066Z","shell.execute_reply":"2023-12-11T08:20:14.338066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Be specific about conditions that can be determined because it may not generate well, such as trying only one model or other performance issues, or making corrections to errors over and over again.**\n\n**Even with the same prompt, the approach may be slightly different, and you may not get to the final result. Therefore, if the model does not work, try again in the following way**\n\n1. Re-run without changing anything.\n2. Write in detail where the error occurs and re-run.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}